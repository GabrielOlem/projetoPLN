{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LOAD DATASET AND GET TOKENS, SLOTS AND INTENTS, AND THEIR INDEXES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_ds(fname):\n",
        "    fname = os.path.join(fname)\n",
        "    with open(fname, 'rb') as stream:\n",
        "        ds, dicts = pickle.load(stream)\n",
        "    print('Done  loading: ', fname)\n",
        "    print('      samples: {:4d}'.format(len(ds['query'])))\n",
        "    print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
        "    print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
        "    print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
        "    return ds, dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Z7t_pA5Jv1",
        "outputId": "f8bbbaa6-e920-415a-a53a-8ef37e100be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done  loading:  atis.train.pkl\n",
            "      samples: 4978\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Done  loading:  atis.test.pkl\n",
            "      samples:  893\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n"
          ]
        }
      ],
      "source": [
        "train_ds, dicts = load_ds('atis.train.pkl')\n",
        "test_ds, _ = load_ds('atis.test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4pQihnEK5bFd"
      },
      "outputs": [],
      "source": [
        "t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids', 'intent_ids'])\n",
        "i2t, i2s, i2in = map(lambda d: {d[k]: k for k in d.keys()}, [t2i, s2i, in2i])\n",
        "query, slots, intent = map(train_ds.get,\n",
        "                           ['query', 'slot_labels', 'intent_labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fQlUy0eLM_oy"
      },
      "outputs": [],
      "source": [
        "t2i_test, s2i_test, in2i_test = map(dicts.get, ['token_ids', 'slot_ids', 'intent_ids'])\n",
        "i2t_test, i2s_test, i2in_test = map(lambda d: {d[k]: k for k in d.keys()}, [t2i_test, s2i_test, in2i_test])\n",
        "query_test, slots_test, intent_test = map(test_ds.get,\n",
        "                           ['query', 'slot_labels', 'intent_labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FORMAT TRAIN AND TEST DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_complete = query + query_test\n",
        "intent_complete = intent + intent_test # TURN INTO A SINGLE DATASET\n",
        "padded_x = pad_sequences(query_complete) # PAD QUERIES FOR UNIFORMIZATION\n",
        "y = tf.keras.utils.to_categorical(intent_complete) # TURN Y FROM CATEGORICAL TO ONE_HOT_ENCODING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_LENGTH = 48\n",
        "EMBEDDING_SIZE = 100\n",
        "UNITS = 128\n",
        "DROPOUT = 0.2\n",
        "### Training parameters\n",
        "LOSS = \"categorical_crossentropy\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL CREATION AND COMPILING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(dicts['token_ids'])+1, EMBEDDING_SIZE, input_length=INPUT_LENGTH))\n",
        "model.add(LSTM(UNITS, return_sequences=True)) #p/ mais de uma camada\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(LSTM(UNITS,return_sequences=False))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(26, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 48, 100)           94400     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 48, 128)           117248    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 26)                3354      \n",
            "=================================================================\n",
            "Total params: 346,586\n",
            "Trainable params: 346,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL FITTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "125/125 - 29s - loss: 1.3505 - accuracy: 0.7191 - val_loss: 1.0969 - val_accuracy: 0.7518\n",
            "Epoch 2/2\n",
            "125/125 - 23s - loss: 1.2151 - accuracy: 0.7256 - val_loss: 1.0196 - val_accuracy: 0.7518\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs=EPOCHS,validation_split=0.15,verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 3s 67ms/step - loss: 1.0753 - accuracy: 0.7421\n",
            "Test loss: 1.0753177404403687 / Test accuracy: 0.7421276569366455\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "fd578b525fe7fcca8a3ea11350d18bcbeb29af20bd1df15f6c5fd2c9cf111483"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
